{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab17.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 17: Random forest and cross validation (10 pts)\n",
    "Please work with your final project partner.\n",
    "  \n",
    "**Submission instruction**: Please create a zip file and a pdf via File -> Print (or cmd + P on mac), and upload it to Gradescope.   Even if you decide to finish it at home, please submit what you have by the end of class to make sure you get some credit!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# edit these names to your name and your final project partner's name\n",
    "me = [\"Rick Marks\"]\n",
    "partner = [\"Piper Marks\"]\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A: Penguins and Random Forest\n",
    "\n",
    "First Decision Trees, now Random Forest.  You do know we are talking about <Penguins>?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to load the penguin dataset as a `pandas` `DataFrame` called `penguins`. I've also supplied code to shorten the penguins species name for convenient exploration and plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "penguins = pd.read_csv(\"palmer_penguins.csv\")\n",
    "\n",
    "# shorten the species name\n",
    "penguins[\"Species\"] = penguins[\"Species\"].str.split().str.get(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For today's exercise, keep only the following columns: `'Species'`, `'Island'`, `'Culmen Length (mm)'`, `'Culmen Depth (mm)'`, `'Flipper Length (mm)'`, `'Body Mass (g)'`, `'Sex'`. Calling `penguins.filter([...])` with the column names inside should make this happen. Reassign this table to `penguins`. The updated `penguins` table should have 344 rows and 7 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here to only keep the columns 'Species', 'Culmen Length (mm)','Island', 'Culmen Depth (mm)', 'Flipper Length (mm)', 'Body Mass (g)','Sex'\n",
    "...\n",
    "penguins.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You might have noticed that your table contains rows with `NaN` values. Calling `penguins.dropna().copy()` will remove these rows and create a completely new table. Do this below, and assign the result to `penguins_clean`. Your updated `penguins_clean` table should have 334 rows and 7 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here to remove rows with NaN values\n",
    "...\n",
    "penguins_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Once again, these `scikit-learn` functions don't know how to handle text variables like `Island` and `Sex`, so we'll have to turn them into numbers for them. You could use boolean indexing like we did in lecture, but the Pandas `replace` method is the fastest way:\n",
    "\n",
    "```Python\n",
    "penguins_clean['Species'] = penguins_clean.Species.replace({'Adelie': 0, 'Chinstrap': 1, 'Gentoo': 2})\n",
    "penguins_clean['Island'] = penguins_clean.Island.replace({'Dream': 0, 'Biscoe': 1, 'Torgersen': 2})\n",
    "penguins_clean['Sex'] = penguins_clean.Sex.replace({'MALE': 0, 'FEMALE': 1, '.' : 2})\n",
    "\n",
    "penguins_clean = penguins_clean.astype(float)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# copy the code and run it here\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Perform a train-test split, with 20% of the data for testing.  Create four new variables: `y_train`, `X_train`, `X_test`, `y_test`.  Do this using like we did in Lab 16 or using the new shorter method shown today in Lecture 22.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to split the data into training and testing sets\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Create a random forest classifier for the penguins with max_depth 3 and 4 trees in it, and print its train and test scores.  See Lecture 22 slides or demo code if you are stuck. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to fit the random forest and evaluate it\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "What do you think about this random forest classifier? Do you think this does a good job at classifying penguin species? Is it better than the decision tree from the last lab?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "[Write your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "And finally, write code to display the 4 trees from the random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to display the 4 trees\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# k-fold cross validation\n",
    "Comparing two models with just a single train/test split can be misleading. To get a better estimate of model performance, we can use k-fold cross validation.\n",
    "Use 5-fold cross validation to evaluate the random forest model from above. Report the accuracy of each of the 5 folds as well as the mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to conduct 5-fold cross-validation on the random forest model\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now try doing 5-fold cross-validation for a decision tree classifier of max_depth 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to conduct 5-fold cross-validation on a single decision tree model and display the results\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "And finally, try doing 5-fold cross-validation for a random forest with 10 trees and max_depth 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here to conduct 5-fold cross-validation on the random forest model with 10 trees and display the results\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You should see that the random forest with 10 trees performs better than the random forest with 4 trees, though results may stiall potentially vary due to randomness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit zip and PDF file to Gradescope Lab 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "name": {
     "name": "name",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert me[0] != 'Rick Marks'\n>>> assert partner[0] != 'Piper Marks'\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
