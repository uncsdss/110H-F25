{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f014df09",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf56109",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89bedbf7-cb85-491c-a637-e6b30f1f41ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <u>Name:</u> [Your name] and (your onyen)\n",
    "\n",
    "I encourage discussing ideas and brainstorming with your peers, but the final text, code, and comments in this homework assignment MUST be 100% written by you as mentioned in syllabus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1e54e-16d4-4a59-8d04-889400a18948",
   "metadata": {},
   "source": [
    "# Homework 5: Summary Statistics, Box Plots, Causation, Correlation  (50 points)\n",
    "\n",
    "Please complete this notebook by filling in the cells provided.\n",
    "\n",
    "!! Please submit the generated **zip** file and a **PDF** of your notebook. You can make a PDF from JupyterHub by 1. File->Print or 2. Command+P (on Mac), then choose 'Save to PDF'. This saves the file on your laptop. All problems will be manually graded, so no need to submit ipynb or zip file. **But you need to make sure all your code is visible and not cut off in the pdf. If we can't see your answer code for a coding problem, points may be deducted.**\n",
    "\n",
    "!! Points will also be **deducted** if you do not include your name and Onyen in the Markdown cell above!!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabcb516",
   "metadata": {},
   "source": [
    "## Problem 1 (15 points) Really?  Burritos again?\n",
    "Well, kind of.  More about the restaurant ratings this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3178709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell!!\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "ratings = pd.read_csv(\"ratings.csv\")\n",
    "burritos_types = pd.read_csv(\"burritos_types.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf873944",
   "metadata": {},
   "source": [
    "**Problem 1.1 (7 points)**. Restaurant ratings.\n",
    "\n",
    "Now we have a different type of plot for restaurant ratings.\n",
    "\n",
    "![ratings.png](./ratings.png)\n",
    "\n",
    "1. (2 points) Try to recreate this plot including the axis labels and title. I used the same fontsizes as the earlier questions. No worries if you get different colors or small cosmetic differences. **Hint**: First decide what type of plot this is, and which seaborn function you need to work with. Then decide which table you need to work with. My solution code is just 5 lines. If you're writing something more complex than this or spending more than 5 to 10 minutes on this, you might be misunderstanding the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7358e230",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9eb75",
   "metadata": {},
   "source": [
    "2. (2 points) Without doing any calculations or coding, do you notice any patterns in the data, i.e. any relationships between ratings from different platforms? Which platform do you \"trust\" more (many valid answers) and does this plot change your opinion on whose ratings to trust more (it's okay if it doesn't)? Make sure to justify your answers. There are many valid answers that can get full credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d642ba",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5bdfd9",
   "metadata": {},
   "source": [
    "3. (2 point) Do you notice anything odd about the Yelp plot? Is it *missing* anything, compared to the other two? Tell us what's missing in this Yelp plot, and why that would be the case. **Hint**: Try running the `describe` function on this table and see if you notice anything interesting that could lead to this observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0032d69",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here! (if you need it)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578b0f2",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57cc300",
   "metadata": {},
   "source": [
    "4. (1 point) Calculate the 3 statistical dispersion measures (discussed in class) for Google. Make sure to show your work with code and/or writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466a90d",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here! (if you need it)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228631b5",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bace267",
   "metadata": {},
   "source": [
    "**Problem 1.2 (6 points)**. Burrito costs (v2).\n",
    "\n",
    "You liked your previous plot so much that you decided to make it again for burritos.\n",
    "\n",
    "![burritos_cost.png](burritos_cost.png)\n",
    "\n",
    "1. (1 point) Make this plot, including the axis labels and title. It's okay if there are small cosmetic differences. Fontsizes are the same as earlier. Again, my solution code is only 5 lines, so if yours is much longer or complicated than that, you might be doing something wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21fde00",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here. Add as many new cells (code or markdown) as you need.\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4cd30a",
   "metadata": {},
   "source": [
    "2. (2 point) Without doing any calculations or coding, what would you say a typical burrito would cost in this town? Is your answer different from Problem 2.2? **Is the distribution plotted here the same as the distribution plotted in Problem 2.2**? Make sure to justify your answers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c305a9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b68b6",
   "metadata": {},
   "source": [
    "3. (1 point) Because of the outlier way up high, the plot is being squished. Can you find out which menu item from which restaurant is causing this problem? **Hint**: My solution uses 1~2 lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036ea1b",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f201ebe6",
   "metadata": {},
   "source": [
    "4. (2 point) What is the average burrito cost **without** this outlier? How much less (rounded to the nearest cent) is this value compared to the average burrito cost **with** the outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7ce30",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Write your code here!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c006c2f",
   "metadata": {},
   "source": [
    "**Problem 1.3 (2 points)**. Translating insights into action.\n",
    "\n",
    "Surprise! You're actually a consultant hired by someone trying to break into the burrito industry in California. You are analyzing this dataset to gain some insight so that you can give good strategy advice to your client. What advice would you give to your client in terms of 1) how much they should charge for each burrito and 2) which reviewing platform (Yelp or Google) they should advertise more heavily on? Why? Make sure to justify your answer by referring to plots and calculations you've made in previous problems. There are many valid answers that would get full credit as long as they are well-justified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b65c62",
   "metadata": {},
   "source": [
    "[Write your answer here!]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb07ddd0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935ad80f",
   "metadata": {},
   "source": [
    "## Problem 2 (17 points) More ROUSes?!?  They don't even exist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd54725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "rouses_model_df = pd.read_csv(\"ROUSes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32007c9",
   "metadata": {},
   "source": [
    "**Problem 2.1 (3 points).** Now add a new feature (column) to `rouses_model_df` for each of the 3 models below, and fill in the feature with data generated by the model.  Name the features `'Length Model 1'`, `'Length Model 2'`, and `'Length Model 3'`.  Note that the first model has a square root; for this you can use `**0.5`.  Hint: if you are unsure of mathematical operation ordering, parentheses are highly recommended!\n",
    "\n",
    "  Length Model 1 = 1.08 * $\\sqrt{Age}$\n",
    "\n",
    "  Length Model 2 = 1.0 + 0.128 * $Age$\n",
    "\n",
    "  Length Model 3 = 1.0 + 0.00229 * $Age^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcbbfa0",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here, replacing ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5860ddec",
   "metadata": {},
   "source": [
    "**Problem 2.2 (2 points).** There are many ways to compare data generated from a model to the actual data.  One of the easiest is to overlay plots of the actual and generated data.  One very simple way to do this is to put multiple scatterplots in the same cell, one after the other; seaborn is smart enough to automatically change the color for each of the plots.  Do this in the below; your plot should look like this: \\\n",
    "![](LengthModel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f4c27",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# write your code here, replacing ...\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30315cd",
   "metadata": {},
   "source": [
    "**Problem 2.3 (1 points).**  Just by looking at the plots, which of the models would you say is the best fit to the actual data?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804530d0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f549292",
   "metadata": {},
   "source": [
    "**Problem 2.4 (2 points).** Summary statistics can also be used to compare data.  For the `Length` data and the data generated by each model, use pandas to help you compute the range to the nearst tenth.  Assign the 4 range values to the corresponding variables in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5806691",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "length_range = ...\n",
    "length_range_model1 = ...\n",
    "length_range_model2 = ...\n",
    "length_range_model3 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9309dfdb",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc1f87",
   "metadata": {},
   "source": [
    "**Problem 2.5 (2 points).** Now do the same for median.  In other words, for the `Length` data and the data generated by each model, use pandas to help you compute the median to the nearst tenth.  Assign the 4 median values to the corresponding variables in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dc59ef",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "length_median = ...\n",
    "length_median_model1 = ...\n",
    "length_median_model2 = ...\n",
    "length_median_model3 = ...\n",
    "print(length_median, length_median_model1, length_median_model2, length_median_model3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8f755",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e273a0a8",
   "metadata": {},
   "source": [
    "**Problem 2.6 (2 points).** Considering the values you computed, which summary statistic (range or median) would be more useful in deciding the model that best approximates the data? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce11845e",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963abab7",
   "metadata": {},
   "source": [
    "**Problem 2.7 (2 points).** Another very useful visualization tool for comparing data is boxplot.  First, execute the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d75267",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(data=rouses_model_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3d14e4",
   "metadata": {},
   "source": [
    "Unfortunately, you should be able to see the Weight column and the Age column are \"dominating\" the plot, and we aren't even interested in them right now.  In the cell below, complete the code you should assign to `new_argument` to create boxplots for only the 4 columns related to *Length*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dd187",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "new_argument = ...\n",
    "sns.boxplot(data=new_argument)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5456ad",
   "metadata": {},
   "source": [
    "**Problem 2.8 (3 points).** Using any technique you wish, decide which of the models below is the best model for `Weight`.  Show some kind of work or visualization in the Python cell, and write what model matches best in the cell below that.\n",
    "\n",
    "  Weight Model 1 = 51 * $\\sqrt{Age}$\n",
    "\n",
    "  Weight Model 2 = 6.9 * $Age$\n",
    "\n",
    "  Weight Model 3 = 0.125 * $Age^2$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a4127",
   "metadata": {
    "tags": [
     "otter_answer_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# show your work here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6e6d9",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf70878",
   "metadata": {},
   "source": [
    "## Problem 3. Correlation (4 points)\n",
    "An important part of data science is understanding the relationships between data.  **Correlation** is the degree to which data change with one another.  **Causality** implies a direct relationship where changes in one thing directly results in changes to another thing.  Data can be correlated without any causality relationship; in fact, this occurs often when the data both depend on a third variable.  For example, number of shark attacks and ice cream sales are often correlated, but one does not cause the other; they both depend on weather conditions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b121fe5c",
   "metadata": {},
   "source": [
    "**Problem 3.1 (1 point).** Run the code below and observe the plot.  Does the ***y*** value appear to be correlated with the ***x*** value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32cef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "x_data = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "y_data = [1,4,7,10,2,5,8,9,6,3,0]\n",
    "sns.scatterplot(x=x_data, y=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff77b7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7627016",
   "metadata": {},
   "source": [
    "**Problem 3.2 (1 point).** What would be your estimate for the correlation coefficient ***r***?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c911b87",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdfd04",
   "metadata": {},
   "source": [
    "**Problem 3.3 (1 point).** Run the code below and observe the plot.  Does the ***y*** value appear to be correlated with the ***x*** value?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69539312",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "y_data = [-10,-13,-14,-16,-18,-20,-21,-24,-26,-27,-30]\n",
    "sns.scatterplot(x=x_data, y=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127fecf",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0465a79",
   "metadata": {},
   "source": [
    "**Problem 3.4 (1 point).** What would be your estimate for the correlation coefficient ***r***?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08b2dce",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9adcda0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit zip file and PDF to Gradescope Homework5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246d9f26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136ce51",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q2.4": {
     "name": "q2.4",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert length_range == 6.9\n>>> assert length_range_model3 == 6.9\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.5": {
     "name": "q2.5",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert length_median == 3.9\n>>> assert length_median_model3 == 1.2\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
